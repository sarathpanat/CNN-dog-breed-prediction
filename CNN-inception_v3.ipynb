{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMvrbGJdLmJ0MsxQj5wXVJG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sarathpanat/CNN-dog-breed-prediction/blob/master/CNN-inception_v3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guuGYbE1yofB",
        "outputId": "e5217624-c7f0-490d-b5e7-74a351fce792",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARJuebQyywtH",
        "outputId": "cba8cc00-9783-4351-a736-a78669bd1775",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import numpy as np\n",
        "from glob import glob\n",
        "\n",
        "dog_files = np.array(glob(\"/content/drive/My Drive/project-dog-classification/project-dog-classification/dogImages/*/*/*\"))\n",
        "dog_train = np.array(glob(\"/content/drive/My Drive/project-dog-classification/project-dog-classification/dogImages/train/*/*\"))\n",
        "\n",
        "print('There are %d total dog images.' % len(dog_files))\n",
        "print('There are %d training dog images.' % len(dog_train))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 8351 total dog images.\n",
            "There are 6680 training dog images.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmt4ymihy8ah",
        "outputId": "9f87f91e-9558-40d0-c405-876f81731e8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#models subpackage contains model architectures for image classification\n",
        "import torch\n",
        "import torchvision.models as models\n",
        "\n",
        "import torch.nn as nn\n",
        "\n",
        "#construct inception model with pre-trained weights\n",
        "inception = models.inception_v3(pretrained=True, aux_logits=False)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# move model to GPU if CUDA is available or to cpu\n",
        "inception = inception.to(device)\n",
        "print(inception)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Inception3(\n",
            "  (Conv2d_1a_3x3): BasicConv2d(\n",
            "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (Conv2d_2a_3x3): BasicConv2d(\n",
            "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (Conv2d_2b_3x3): BasicConv2d(\n",
            "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (Conv2d_3b_1x1): BasicConv2d(\n",
            "    (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (Conv2d_4a_3x3): BasicConv2d(\n",
            "    (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (Mixed_5b): InceptionA(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_1): BasicConv2d(\n",
            "      (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_2): BasicConv2d(\n",
            "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_5c): InceptionA(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_1): BasicConv2d(\n",
            "      (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_2): BasicConv2d(\n",
            "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_5d): InceptionA(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_1): BasicConv2d(\n",
            "      (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_2): BasicConv2d(\n",
            "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_6a): InceptionB(\n",
            "    (branch3x3): BasicConv2d(\n",
            "      (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_6b): InceptionC(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_2): BasicConv2d(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_3): BasicConv2d(\n",
            "      (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_4): BasicConv2d(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_5): BasicConv2d(\n",
            "      (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_6c): InceptionC(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_2): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_3): BasicConv2d(\n",
            "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_4): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_5): BasicConv2d(\n",
            "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_6d): InceptionC(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_2): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_3): BasicConv2d(\n",
            "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_4): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_5): BasicConv2d(\n",
            "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_6e): InceptionC(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_2): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_3): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_4): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_5): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_7a): InceptionD(\n",
            "    (branch3x3_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_2): BasicConv2d(\n",
            "      (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7x3_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7x3_2): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7x3_3): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7x3_4): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_7b): InceptionE(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_1): BasicConv2d(\n",
            "      (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_2a): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_2b): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3a): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3b): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_7c): InceptionE(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_1): BasicConv2d(\n",
            "      (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_2a): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_2b): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3a): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3b): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUY4Ftndy0Zw"
      },
      "source": [
        "import os\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomRotation(20),\n",
        "        transforms.RandomResizedCrop(299),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'valid': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "data_dir = '/content/drive/My Drive/project-dog-classification/project-dog-classification/dogImages/'\n",
        "\n",
        "images_data = {p: datasets.ImageFolder(os.path.join(data_dir, p), \n",
        "                                       data_transforms[p]) \n",
        "               for p in ['train', 'valid', 'test']}\n",
        "\n",
        "dataloaders = {p: torch.utils.data.DataLoader(images_data[p], batch_size=64, \n",
        "                                              shuffle=True, num_workers=4)\n",
        "               for p in ['train', 'valid', 'test']}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40yDzQLQzBW2",
        "outputId": "99ef90b9-388b-4c0c-c90d-5eaf001b847a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from collections import OrderedDict\n",
        "for param in inception.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "fc = nn.Sequential(OrderedDict([\n",
        "     ('fc',nn.Linear(2048,len(images_data['train'].classes))),\n",
        "     ('output',nn.LogSoftmax(dim=1))\n",
        "]))\n",
        "\n",
        "inception.fc = fc\n",
        "inception.to(device)\n",
        "\n",
        "print(inception)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Inception3(\n",
            "  (Conv2d_1a_3x3): BasicConv2d(\n",
            "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (Conv2d_2a_3x3): BasicConv2d(\n",
            "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (Conv2d_2b_3x3): BasicConv2d(\n",
            "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (Conv2d_3b_1x1): BasicConv2d(\n",
            "    (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (Conv2d_4a_3x3): BasicConv2d(\n",
            "    (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (Mixed_5b): InceptionA(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_1): BasicConv2d(\n",
            "      (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_2): BasicConv2d(\n",
            "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_5c): InceptionA(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_1): BasicConv2d(\n",
            "      (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_2): BasicConv2d(\n",
            "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_5d): InceptionA(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_1): BasicConv2d(\n",
            "      (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_2): BasicConv2d(\n",
            "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_6a): InceptionB(\n",
            "    (branch3x3): BasicConv2d(\n",
            "      (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_6b): InceptionC(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_2): BasicConv2d(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_3): BasicConv2d(\n",
            "      (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_4): BasicConv2d(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_5): BasicConv2d(\n",
            "      (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_6c): InceptionC(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_2): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_3): BasicConv2d(\n",
            "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_4): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_5): BasicConv2d(\n",
            "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_6d): InceptionC(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_2): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_3): BasicConv2d(\n",
            "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_4): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_5): BasicConv2d(\n",
            "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_6e): InceptionC(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_2): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_3): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_4): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_5): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_7a): InceptionD(\n",
            "    (branch3x3_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_2): BasicConv2d(\n",
            "      (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7x3_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7x3_2): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7x3_3): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7x3_4): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_7b): InceptionE(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_1): BasicConv2d(\n",
            "      (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_2a): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_2b): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3a): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3b): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_7c): InceptionE(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_1): BasicConv2d(\n",
            "      (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_2a): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_2b): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3a): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3b): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (fc): Sequential(\n",
            "    (fc): Linear(in_features=2048, out_features=133, bias=True)\n",
            "    (output): LogSoftmax(dim=1)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ly2KJzDEzaBq",
        "outputId": "8f40def1-f46b-499f-8cf8-ceb9823d60a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from torchsummary import summary\n",
        "summary(inception, (3, 299, 299))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 32, 149, 149]             864\n",
            "       BatchNorm2d-2         [-1, 32, 149, 149]              64\n",
            "       BasicConv2d-3         [-1, 32, 149, 149]               0\n",
            "            Conv2d-4         [-1, 32, 147, 147]           9,216\n",
            "       BatchNorm2d-5         [-1, 32, 147, 147]              64\n",
            "       BasicConv2d-6         [-1, 32, 147, 147]               0\n",
            "            Conv2d-7         [-1, 64, 147, 147]          18,432\n",
            "       BatchNorm2d-8         [-1, 64, 147, 147]             128\n",
            "       BasicConv2d-9         [-1, 64, 147, 147]               0\n",
            "        MaxPool2d-10           [-1, 64, 73, 73]               0\n",
            "           Conv2d-11           [-1, 80, 73, 73]           5,120\n",
            "      BatchNorm2d-12           [-1, 80, 73, 73]             160\n",
            "      BasicConv2d-13           [-1, 80, 73, 73]               0\n",
            "           Conv2d-14          [-1, 192, 71, 71]         138,240\n",
            "      BatchNorm2d-15          [-1, 192, 71, 71]             384\n",
            "      BasicConv2d-16          [-1, 192, 71, 71]               0\n",
            "        MaxPool2d-17          [-1, 192, 35, 35]               0\n",
            "           Conv2d-18           [-1, 64, 35, 35]          12,288\n",
            "      BatchNorm2d-19           [-1, 64, 35, 35]             128\n",
            "      BasicConv2d-20           [-1, 64, 35, 35]               0\n",
            "           Conv2d-21           [-1, 48, 35, 35]           9,216\n",
            "      BatchNorm2d-22           [-1, 48, 35, 35]              96\n",
            "      BasicConv2d-23           [-1, 48, 35, 35]               0\n",
            "           Conv2d-24           [-1, 64, 35, 35]          76,800\n",
            "      BatchNorm2d-25           [-1, 64, 35, 35]             128\n",
            "      BasicConv2d-26           [-1, 64, 35, 35]               0\n",
            "           Conv2d-27           [-1, 64, 35, 35]          12,288\n",
            "      BatchNorm2d-28           [-1, 64, 35, 35]             128\n",
            "      BasicConv2d-29           [-1, 64, 35, 35]               0\n",
            "           Conv2d-30           [-1, 96, 35, 35]          55,296\n",
            "      BatchNorm2d-31           [-1, 96, 35, 35]             192\n",
            "      BasicConv2d-32           [-1, 96, 35, 35]               0\n",
            "           Conv2d-33           [-1, 96, 35, 35]          82,944\n",
            "      BatchNorm2d-34           [-1, 96, 35, 35]             192\n",
            "      BasicConv2d-35           [-1, 96, 35, 35]               0\n",
            "           Conv2d-36           [-1, 32, 35, 35]           6,144\n",
            "      BatchNorm2d-37           [-1, 32, 35, 35]              64\n",
            "      BasicConv2d-38           [-1, 32, 35, 35]               0\n",
            "       InceptionA-39          [-1, 256, 35, 35]               0\n",
            "           Conv2d-40           [-1, 64, 35, 35]          16,384\n",
            "      BatchNorm2d-41           [-1, 64, 35, 35]             128\n",
            "      BasicConv2d-42           [-1, 64, 35, 35]               0\n",
            "           Conv2d-43           [-1, 48, 35, 35]          12,288\n",
            "      BatchNorm2d-44           [-1, 48, 35, 35]              96\n",
            "      BasicConv2d-45           [-1, 48, 35, 35]               0\n",
            "           Conv2d-46           [-1, 64, 35, 35]          76,800\n",
            "      BatchNorm2d-47           [-1, 64, 35, 35]             128\n",
            "      BasicConv2d-48           [-1, 64, 35, 35]               0\n",
            "           Conv2d-49           [-1, 64, 35, 35]          16,384\n",
            "      BatchNorm2d-50           [-1, 64, 35, 35]             128\n",
            "      BasicConv2d-51           [-1, 64, 35, 35]               0\n",
            "           Conv2d-52           [-1, 96, 35, 35]          55,296\n",
            "      BatchNorm2d-53           [-1, 96, 35, 35]             192\n",
            "      BasicConv2d-54           [-1, 96, 35, 35]               0\n",
            "           Conv2d-55           [-1, 96, 35, 35]          82,944\n",
            "      BatchNorm2d-56           [-1, 96, 35, 35]             192\n",
            "      BasicConv2d-57           [-1, 96, 35, 35]               0\n",
            "           Conv2d-58           [-1, 64, 35, 35]          16,384\n",
            "      BatchNorm2d-59           [-1, 64, 35, 35]             128\n",
            "      BasicConv2d-60           [-1, 64, 35, 35]               0\n",
            "       InceptionA-61          [-1, 288, 35, 35]               0\n",
            "           Conv2d-62           [-1, 64, 35, 35]          18,432\n",
            "      BatchNorm2d-63           [-1, 64, 35, 35]             128\n",
            "      BasicConv2d-64           [-1, 64, 35, 35]               0\n",
            "           Conv2d-65           [-1, 48, 35, 35]          13,824\n",
            "      BatchNorm2d-66           [-1, 48, 35, 35]              96\n",
            "      BasicConv2d-67           [-1, 48, 35, 35]               0\n",
            "           Conv2d-68           [-1, 64, 35, 35]          76,800\n",
            "      BatchNorm2d-69           [-1, 64, 35, 35]             128\n",
            "      BasicConv2d-70           [-1, 64, 35, 35]               0\n",
            "           Conv2d-71           [-1, 64, 35, 35]          18,432\n",
            "      BatchNorm2d-72           [-1, 64, 35, 35]             128\n",
            "      BasicConv2d-73           [-1, 64, 35, 35]               0\n",
            "           Conv2d-74           [-1, 96, 35, 35]          55,296\n",
            "      BatchNorm2d-75           [-1, 96, 35, 35]             192\n",
            "      BasicConv2d-76           [-1, 96, 35, 35]               0\n",
            "           Conv2d-77           [-1, 96, 35, 35]          82,944\n",
            "      BatchNorm2d-78           [-1, 96, 35, 35]             192\n",
            "      BasicConv2d-79           [-1, 96, 35, 35]               0\n",
            "           Conv2d-80           [-1, 64, 35, 35]          18,432\n",
            "      BatchNorm2d-81           [-1, 64, 35, 35]             128\n",
            "      BasicConv2d-82           [-1, 64, 35, 35]               0\n",
            "       InceptionA-83          [-1, 288, 35, 35]               0\n",
            "           Conv2d-84          [-1, 384, 17, 17]         995,328\n",
            "      BatchNorm2d-85          [-1, 384, 17, 17]             768\n",
            "      BasicConv2d-86          [-1, 384, 17, 17]               0\n",
            "           Conv2d-87           [-1, 64, 35, 35]          18,432\n",
            "      BatchNorm2d-88           [-1, 64, 35, 35]             128\n",
            "      BasicConv2d-89           [-1, 64, 35, 35]               0\n",
            "           Conv2d-90           [-1, 96, 35, 35]          55,296\n",
            "      BatchNorm2d-91           [-1, 96, 35, 35]             192\n",
            "      BasicConv2d-92           [-1, 96, 35, 35]               0\n",
            "           Conv2d-93           [-1, 96, 17, 17]          82,944\n",
            "      BatchNorm2d-94           [-1, 96, 17, 17]             192\n",
            "      BasicConv2d-95           [-1, 96, 17, 17]               0\n",
            "       InceptionB-96          [-1, 768, 17, 17]               0\n",
            "           Conv2d-97          [-1, 192, 17, 17]         147,456\n",
            "      BatchNorm2d-98          [-1, 192, 17, 17]             384\n",
            "      BasicConv2d-99          [-1, 192, 17, 17]               0\n",
            "          Conv2d-100          [-1, 128, 17, 17]          98,304\n",
            "     BatchNorm2d-101          [-1, 128, 17, 17]             256\n",
            "     BasicConv2d-102          [-1, 128, 17, 17]               0\n",
            "          Conv2d-103          [-1, 128, 17, 17]         114,688\n",
            "     BatchNorm2d-104          [-1, 128, 17, 17]             256\n",
            "     BasicConv2d-105          [-1, 128, 17, 17]               0\n",
            "          Conv2d-106          [-1, 192, 17, 17]         172,032\n",
            "     BatchNorm2d-107          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-108          [-1, 192, 17, 17]               0\n",
            "          Conv2d-109          [-1, 128, 17, 17]          98,304\n",
            "     BatchNorm2d-110          [-1, 128, 17, 17]             256\n",
            "     BasicConv2d-111          [-1, 128, 17, 17]               0\n",
            "          Conv2d-112          [-1, 128, 17, 17]         114,688\n",
            "     BatchNorm2d-113          [-1, 128, 17, 17]             256\n",
            "     BasicConv2d-114          [-1, 128, 17, 17]               0\n",
            "          Conv2d-115          [-1, 128, 17, 17]         114,688\n",
            "     BatchNorm2d-116          [-1, 128, 17, 17]             256\n",
            "     BasicConv2d-117          [-1, 128, 17, 17]               0\n",
            "          Conv2d-118          [-1, 128, 17, 17]         114,688\n",
            "     BatchNorm2d-119          [-1, 128, 17, 17]             256\n",
            "     BasicConv2d-120          [-1, 128, 17, 17]               0\n",
            "          Conv2d-121          [-1, 192, 17, 17]         172,032\n",
            "     BatchNorm2d-122          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-123          [-1, 192, 17, 17]               0\n",
            "          Conv2d-124          [-1, 192, 17, 17]         147,456\n",
            "     BatchNorm2d-125          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-126          [-1, 192, 17, 17]               0\n",
            "      InceptionC-127          [-1, 768, 17, 17]               0\n",
            "          Conv2d-128          [-1, 192, 17, 17]         147,456\n",
            "     BatchNorm2d-129          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-130          [-1, 192, 17, 17]               0\n",
            "          Conv2d-131          [-1, 160, 17, 17]         122,880\n",
            "     BatchNorm2d-132          [-1, 160, 17, 17]             320\n",
            "     BasicConv2d-133          [-1, 160, 17, 17]               0\n",
            "          Conv2d-134          [-1, 160, 17, 17]         179,200\n",
            "     BatchNorm2d-135          [-1, 160, 17, 17]             320\n",
            "     BasicConv2d-136          [-1, 160, 17, 17]               0\n",
            "          Conv2d-137          [-1, 192, 17, 17]         215,040\n",
            "     BatchNorm2d-138          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-139          [-1, 192, 17, 17]               0\n",
            "          Conv2d-140          [-1, 160, 17, 17]         122,880\n",
            "     BatchNorm2d-141          [-1, 160, 17, 17]             320\n",
            "     BasicConv2d-142          [-1, 160, 17, 17]               0\n",
            "          Conv2d-143          [-1, 160, 17, 17]         179,200\n",
            "     BatchNorm2d-144          [-1, 160, 17, 17]             320\n",
            "     BasicConv2d-145          [-1, 160, 17, 17]               0\n",
            "          Conv2d-146          [-1, 160, 17, 17]         179,200\n",
            "     BatchNorm2d-147          [-1, 160, 17, 17]             320\n",
            "     BasicConv2d-148          [-1, 160, 17, 17]               0\n",
            "          Conv2d-149          [-1, 160, 17, 17]         179,200\n",
            "     BatchNorm2d-150          [-1, 160, 17, 17]             320\n",
            "     BasicConv2d-151          [-1, 160, 17, 17]               0\n",
            "          Conv2d-152          [-1, 192, 17, 17]         215,040\n",
            "     BatchNorm2d-153          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-154          [-1, 192, 17, 17]               0\n",
            "          Conv2d-155          [-1, 192, 17, 17]         147,456\n",
            "     BatchNorm2d-156          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-157          [-1, 192, 17, 17]               0\n",
            "      InceptionC-158          [-1, 768, 17, 17]               0\n",
            "          Conv2d-159          [-1, 192, 17, 17]         147,456\n",
            "     BatchNorm2d-160          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-161          [-1, 192, 17, 17]               0\n",
            "          Conv2d-162          [-1, 160, 17, 17]         122,880\n",
            "     BatchNorm2d-163          [-1, 160, 17, 17]             320\n",
            "     BasicConv2d-164          [-1, 160, 17, 17]               0\n",
            "          Conv2d-165          [-1, 160, 17, 17]         179,200\n",
            "     BatchNorm2d-166          [-1, 160, 17, 17]             320\n",
            "     BasicConv2d-167          [-1, 160, 17, 17]               0\n",
            "          Conv2d-168          [-1, 192, 17, 17]         215,040\n",
            "     BatchNorm2d-169          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-170          [-1, 192, 17, 17]               0\n",
            "          Conv2d-171          [-1, 160, 17, 17]         122,880\n",
            "     BatchNorm2d-172          [-1, 160, 17, 17]             320\n",
            "     BasicConv2d-173          [-1, 160, 17, 17]               0\n",
            "          Conv2d-174          [-1, 160, 17, 17]         179,200\n",
            "     BatchNorm2d-175          [-1, 160, 17, 17]             320\n",
            "     BasicConv2d-176          [-1, 160, 17, 17]               0\n",
            "          Conv2d-177          [-1, 160, 17, 17]         179,200\n",
            "     BatchNorm2d-178          [-1, 160, 17, 17]             320\n",
            "     BasicConv2d-179          [-1, 160, 17, 17]               0\n",
            "          Conv2d-180          [-1, 160, 17, 17]         179,200\n",
            "     BatchNorm2d-181          [-1, 160, 17, 17]             320\n",
            "     BasicConv2d-182          [-1, 160, 17, 17]               0\n",
            "          Conv2d-183          [-1, 192, 17, 17]         215,040\n",
            "     BatchNorm2d-184          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-185          [-1, 192, 17, 17]               0\n",
            "          Conv2d-186          [-1, 192, 17, 17]         147,456\n",
            "     BatchNorm2d-187          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-188          [-1, 192, 17, 17]               0\n",
            "      InceptionC-189          [-1, 768, 17, 17]               0\n",
            "          Conv2d-190          [-1, 192, 17, 17]         147,456\n",
            "     BatchNorm2d-191          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-192          [-1, 192, 17, 17]               0\n",
            "          Conv2d-193          [-1, 192, 17, 17]         147,456\n",
            "     BatchNorm2d-194          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-195          [-1, 192, 17, 17]               0\n",
            "          Conv2d-196          [-1, 192, 17, 17]         258,048\n",
            "     BatchNorm2d-197          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-198          [-1, 192, 17, 17]               0\n",
            "          Conv2d-199          [-1, 192, 17, 17]         258,048\n",
            "     BatchNorm2d-200          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-201          [-1, 192, 17, 17]               0\n",
            "          Conv2d-202          [-1, 192, 17, 17]         147,456\n",
            "     BatchNorm2d-203          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-204          [-1, 192, 17, 17]               0\n",
            "          Conv2d-205          [-1, 192, 17, 17]         258,048\n",
            "     BatchNorm2d-206          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-207          [-1, 192, 17, 17]               0\n",
            "          Conv2d-208          [-1, 192, 17, 17]         258,048\n",
            "     BatchNorm2d-209          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-210          [-1, 192, 17, 17]               0\n",
            "          Conv2d-211          [-1, 192, 17, 17]         258,048\n",
            "     BatchNorm2d-212          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-213          [-1, 192, 17, 17]               0\n",
            "          Conv2d-214          [-1, 192, 17, 17]         258,048\n",
            "     BatchNorm2d-215          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-216          [-1, 192, 17, 17]               0\n",
            "          Conv2d-217          [-1, 192, 17, 17]         147,456\n",
            "     BatchNorm2d-218          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-219          [-1, 192, 17, 17]               0\n",
            "      InceptionC-220          [-1, 768, 17, 17]               0\n",
            "          Conv2d-221          [-1, 192, 17, 17]         147,456\n",
            "     BatchNorm2d-222          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-223          [-1, 192, 17, 17]               0\n",
            "          Conv2d-224            [-1, 320, 8, 8]         552,960\n",
            "     BatchNorm2d-225            [-1, 320, 8, 8]             640\n",
            "     BasicConv2d-226            [-1, 320, 8, 8]               0\n",
            "          Conv2d-227          [-1, 192, 17, 17]         147,456\n",
            "     BatchNorm2d-228          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-229          [-1, 192, 17, 17]               0\n",
            "          Conv2d-230          [-1, 192, 17, 17]         258,048\n",
            "     BatchNorm2d-231          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-232          [-1, 192, 17, 17]               0\n",
            "          Conv2d-233          [-1, 192, 17, 17]         258,048\n",
            "     BatchNorm2d-234          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-235          [-1, 192, 17, 17]               0\n",
            "          Conv2d-236            [-1, 192, 8, 8]         331,776\n",
            "     BatchNorm2d-237            [-1, 192, 8, 8]             384\n",
            "     BasicConv2d-238            [-1, 192, 8, 8]               0\n",
            "      InceptionD-239           [-1, 1280, 8, 8]               0\n",
            "          Conv2d-240            [-1, 320, 8, 8]         409,600\n",
            "     BatchNorm2d-241            [-1, 320, 8, 8]             640\n",
            "     BasicConv2d-242            [-1, 320, 8, 8]               0\n",
            "          Conv2d-243            [-1, 384, 8, 8]         491,520\n",
            "     BatchNorm2d-244            [-1, 384, 8, 8]             768\n",
            "     BasicConv2d-245            [-1, 384, 8, 8]               0\n",
            "          Conv2d-246            [-1, 384, 8, 8]         442,368\n",
            "     BatchNorm2d-247            [-1, 384, 8, 8]             768\n",
            "     BasicConv2d-248            [-1, 384, 8, 8]               0\n",
            "          Conv2d-249            [-1, 384, 8, 8]         442,368\n",
            "     BatchNorm2d-250            [-1, 384, 8, 8]             768\n",
            "     BasicConv2d-251            [-1, 384, 8, 8]               0\n",
            "          Conv2d-252            [-1, 448, 8, 8]         573,440\n",
            "     BatchNorm2d-253            [-1, 448, 8, 8]             896\n",
            "     BasicConv2d-254            [-1, 448, 8, 8]               0\n",
            "          Conv2d-255            [-1, 384, 8, 8]       1,548,288\n",
            "     BatchNorm2d-256            [-1, 384, 8, 8]             768\n",
            "     BasicConv2d-257            [-1, 384, 8, 8]               0\n",
            "          Conv2d-258            [-1, 384, 8, 8]         442,368\n",
            "     BatchNorm2d-259            [-1, 384, 8, 8]             768\n",
            "     BasicConv2d-260            [-1, 384, 8, 8]               0\n",
            "          Conv2d-261            [-1, 384, 8, 8]         442,368\n",
            "     BatchNorm2d-262            [-1, 384, 8, 8]             768\n",
            "     BasicConv2d-263            [-1, 384, 8, 8]               0\n",
            "          Conv2d-264            [-1, 192, 8, 8]         245,760\n",
            "     BatchNorm2d-265            [-1, 192, 8, 8]             384\n",
            "     BasicConv2d-266            [-1, 192, 8, 8]               0\n",
            "      InceptionE-267           [-1, 2048, 8, 8]               0\n",
            "          Conv2d-268            [-1, 320, 8, 8]         655,360\n",
            "     BatchNorm2d-269            [-1, 320, 8, 8]             640\n",
            "     BasicConv2d-270            [-1, 320, 8, 8]               0\n",
            "          Conv2d-271            [-1, 384, 8, 8]         786,432\n",
            "     BatchNorm2d-272            [-1, 384, 8, 8]             768\n",
            "     BasicConv2d-273            [-1, 384, 8, 8]               0\n",
            "          Conv2d-274            [-1, 384, 8, 8]         442,368\n",
            "     BatchNorm2d-275            [-1, 384, 8, 8]             768\n",
            "     BasicConv2d-276            [-1, 384, 8, 8]               0\n",
            "          Conv2d-277            [-1, 384, 8, 8]         442,368\n",
            "     BatchNorm2d-278            [-1, 384, 8, 8]             768\n",
            "     BasicConv2d-279            [-1, 384, 8, 8]               0\n",
            "          Conv2d-280            [-1, 448, 8, 8]         917,504\n",
            "     BatchNorm2d-281            [-1, 448, 8, 8]             896\n",
            "     BasicConv2d-282            [-1, 448, 8, 8]               0\n",
            "          Conv2d-283            [-1, 384, 8, 8]       1,548,288\n",
            "     BatchNorm2d-284            [-1, 384, 8, 8]             768\n",
            "     BasicConv2d-285            [-1, 384, 8, 8]               0\n",
            "          Conv2d-286            [-1, 384, 8, 8]         442,368\n",
            "     BatchNorm2d-287            [-1, 384, 8, 8]             768\n",
            "     BasicConv2d-288            [-1, 384, 8, 8]               0\n",
            "          Conv2d-289            [-1, 384, 8, 8]         442,368\n",
            "     BatchNorm2d-290            [-1, 384, 8, 8]             768\n",
            "     BasicConv2d-291            [-1, 384, 8, 8]               0\n",
            "          Conv2d-292            [-1, 192, 8, 8]         393,216\n",
            "     BatchNorm2d-293            [-1, 192, 8, 8]             384\n",
            "     BasicConv2d-294            [-1, 192, 8, 8]               0\n",
            "      InceptionE-295           [-1, 2048, 8, 8]               0\n",
            "AdaptiveAvgPool2d-296           [-1, 2048, 1, 1]               0\n",
            "         Dropout-297           [-1, 2048, 1, 1]               0\n",
            "          Linear-298                  [-1, 133]         272,517\n",
            "      LogSoftmax-299                  [-1, 133]               0\n",
            "================================================================\n",
            "Total params: 22,058,085\n",
            "Trainable params: 272,517\n",
            "Non-trainable params: 21,785,568\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 1.02\n",
            "Forward/backward pass size (MB): 228.55\n",
            "Params size (MB): 84.14\n",
            "Estimated Total Size (MB): 313.71\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DGoMNiozF8o"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "### TODO: select loss function\n",
        "criterion_scratch = nn.CrossEntropyLoss()\n",
        "\n",
        "### TODO: select optimizer\n",
        "# optimizer_inception = optim.Adam(model_scratch.parameters(), lr=0.001, momentum=0.9)\n",
        "optimizer_scratch = optim.Adam(inception.parameters(), lr=0.001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EqBgZKbzIiX"
      },
      "source": [
        "from PIL import ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES=True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7AaMEjNzKKM"
      },
      "source": [
        "def train(n_epochs, loaders, model, optimizer, criterion, device, save_path):\n",
        "    \"\"\"returns trained model\"\"\"\n",
        "    # initialize tracker for minimum validation loss\n",
        "    valid_loss_min = np.Inf \n",
        "    \n",
        "    for epoch in range(1, n_epochs+1):\n",
        "        # initialize variables to monitor training and validation loss\n",
        "        train_loss = 0.0\n",
        "        valid_loss = 0.0\n",
        "        \n",
        "        ###################\n",
        "        # train the model #\n",
        "        ###################\n",
        "        model.train()\n",
        "        for batch_idx, (data, target) in enumerate(loaders['train']):\n",
        "            # move to GPU or CPU\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            \n",
        "            ## find the loss and update the model parameters accordingly\n",
        "            ## record the average training loss, using something like\n",
        "            ## train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            \n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            train_loss += ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n",
        "            \n",
        "        ######################    \n",
        "        # validate the model #\n",
        "        ######################\n",
        "        model.eval()\n",
        "        for batch_idx, (data, target) in enumerate(loaders['valid']):\n",
        "            # move to GPU or CPU\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            \n",
        "            ## update the average validation loss\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            \n",
        "            valid_loss += ((1 / (batch_idx + 1)) * (loss.data - valid_loss))\n",
        "            \n",
        "        # print training/validation statistics \n",
        "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
        "            epoch, \n",
        "            train_loss,\n",
        "            valid_loss\n",
        "            ))\n",
        "        \n",
        "        ## TODO: save the model if validation loss has decreased\n",
        "        if valid_loss < valid_loss_min:\n",
        "            print('Saving model..')\n",
        "            valid_loss_min = valid_loss\n",
        "            torch.save(model.state_dict(), save_path)\n",
        "            \n",
        "    # return trained model\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZoTnnT2zOdk",
        "outputId": "ad8ff378-2de5-4c1c-da4a-c354acec9ebb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        }
      },
      "source": [
        "inception2 = train(30, dataloaders, resnet18, optimizer_scratch, \n",
        "                      criterion_scratch, device, 'inception2.pt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 \tTraining Loss: 3.329044 \tValidation Loss: 0.892375\n",
            "Saving model..\n",
            "Epoch: 2 \tTraining Loss: 1.698378 \tValidation Loss: 0.755382\n",
            "Saving model..\n",
            "Epoch: 3 \tTraining Loss: 1.335221 \tValidation Loss: 0.687160\n",
            "Saving model..\n",
            "Epoch: 4 \tTraining Loss: 1.216069 \tValidation Loss: 0.686021\n",
            "Saving model..\n",
            "Epoch: 5 \tTraining Loss: 1.132868 \tValidation Loss: 0.669559\n",
            "Saving model..\n",
            "Epoch: 6 \tTraining Loss: 1.046515 \tValidation Loss: 0.629739\n",
            "Saving model..\n",
            "Epoch: 7 \tTraining Loss: 1.031982 \tValidation Loss: 0.596398\n",
            "Saving model..\n",
            "Epoch: 8 \tTraining Loss: 0.984553 \tValidation Loss: 0.604943\n",
            "Epoch: 9 \tTraining Loss: 0.967358 \tValidation Loss: 0.645473\n",
            "Epoch: 10 \tTraining Loss: 0.967447 \tValidation Loss: 0.672472\n",
            "Epoch: 11 \tTraining Loss: 0.910595 \tValidation Loss: 0.651557\n",
            "Epoch: 12 \tTraining Loss: 0.932173 \tValidation Loss: 0.633538\n",
            "Epoch: 13 \tTraining Loss: 0.909841 \tValidation Loss: 0.603627\n",
            "Epoch: 14 \tTraining Loss: 0.904366 \tValidation Loss: 0.756788\n",
            "Epoch: 15 \tTraining Loss: 0.916865 \tValidation Loss: 0.730424\n",
            "Epoch: 16 \tTraining Loss: 0.880904 \tValidation Loss: 0.697914\n",
            "Epoch: 17 \tTraining Loss: 0.892722 \tValidation Loss: 0.645740\n",
            "Epoch: 18 \tTraining Loss: 0.852603 \tValidation Loss: 0.725849\n",
            "Epoch: 19 \tTraining Loss: 0.900508 \tValidation Loss: 0.665856\n",
            "Epoch: 20 \tTraining Loss: 0.864131 \tValidation Loss: 0.735032\n",
            "Epoch: 21 \tTraining Loss: 0.834708 \tValidation Loss: 0.640207\n",
            "Epoch: 22 \tTraining Loss: 0.888095 \tValidation Loss: 0.721026\n",
            "Epoch: 23 \tTraining Loss: 0.855581 \tValidation Loss: 0.676025\n",
            "Epoch: 24 \tTraining Loss: 0.851007 \tValidation Loss: 0.695443\n",
            "Epoch: 25 \tTraining Loss: 0.851781 \tValidation Loss: 0.752085\n",
            "Epoch: 26 \tTraining Loss: 0.818233 \tValidation Loss: 0.681271\n",
            "Epoch: 27 \tTraining Loss: 0.846711 \tValidation Loss: 0.699101\n",
            "Epoch: 28 \tTraining Loss: 0.838526 \tValidation Loss: 0.691205\n",
            "Epoch: 29 \tTraining Loss: 0.840982 \tValidation Loss: 0.702474\n",
            "Epoch: 30 \tTraining Loss: 0.842728 \tValidation Loss: 0.822274\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gN0pRN155Wqz",
        "outputId": "b9d08d26-de70-4349-aa2d-d65a06d3e5d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "inception2.load_state_dict(torch.load('inception2.pt'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UDhkCjLLAmm"
      },
      "source": [
        "def test(loaders, model, criterion, device):\n",
        "\n",
        "    # monitor test loss and accuracy\n",
        "    test_loss = 0.\n",
        "    correct = 0.\n",
        "    total = 0.\n",
        "\n",
        "    model.eval()\n",
        "    for batch_idx, (data, target) in enumerate(loaders['test']):\n",
        "        # move to GPU or CPU\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        \n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        output = model(data)\n",
        "        # calculate the loss\n",
        "        loss = criterion(output, target)\n",
        "        # update average test loss \n",
        "        test_loss = test_loss + ((1 / (batch_idx + 1)) * (loss.data - test_loss))\n",
        "        # convert output probabilities to predicted class\n",
        "        pred = output.data.max(1, keepdim=True)[1]\n",
        "        # compare predictions to true label\n",
        "        correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n",
        "        total += data.size(0)\n",
        "            \n",
        "    print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
        "\n",
        "    print('\\nTest Accuracy: %2d%% (%2d/%2d)' % (\n",
        "        100. * correct / total, correct, total))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vliapdTVK1Bz",
        "outputId": "506f71c2-eefa-43fc-9bf6-0e55bc3f3557",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "test(dataloaders, inception, criterion_scratch, device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.734207\n",
            "\n",
            "\n",
            "Test Accuracy: 81% (684/836)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnLt-d_pko8H",
        "outputId": "b7101b79-55b0-4fa2-9546-ebc258eba8fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "inception_3 = train(100, dataloaders, inception, optimizer_scratch, \n",
        "                      criterion_scratch, device, 'inception_3.pt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 \tTraining Loss: 3.334334 \tValidation Loss: 1.042374\n",
            "Saving model..\n",
            "Epoch: 2 \tTraining Loss: 1.708880 \tValidation Loss: 0.681924\n",
            "Saving model..\n",
            "Epoch: 3 \tTraining Loss: 1.337258 \tValidation Loss: 0.793185\n",
            "Epoch: 4 \tTraining Loss: 1.221940 \tValidation Loss: 0.656210\n",
            "Saving model..\n",
            "Epoch: 5 \tTraining Loss: 1.107261 \tValidation Loss: 0.613280\n",
            "Saving model..\n",
            "Epoch: 6 \tTraining Loss: 1.068344 \tValidation Loss: 0.611767\n",
            "Saving model..\n",
            "Epoch: 7 \tTraining Loss: 1.025156 \tValidation Loss: 0.618616\n",
            "Epoch: 8 \tTraining Loss: 1.010044 \tValidation Loss: 0.621361\n",
            "Epoch: 9 \tTraining Loss: 0.963864 \tValidation Loss: 0.627966\n",
            "Epoch: 10 \tTraining Loss: 0.962499 \tValidation Loss: 0.593399\n",
            "Saving model..\n",
            "Epoch: 11 \tTraining Loss: 0.934811 \tValidation Loss: 0.647555\n",
            "Epoch: 12 \tTraining Loss: 0.906864 \tValidation Loss: 0.607858\n",
            "Epoch: 13 \tTraining Loss: 0.902198 \tValidation Loss: 0.624786\n",
            "Epoch: 14 \tTraining Loss: 0.897774 \tValidation Loss: 0.671481\n",
            "Epoch: 15 \tTraining Loss: 0.881846 \tValidation Loss: 0.735744\n",
            "Epoch: 16 \tTraining Loss: 0.868992 \tValidation Loss: 0.647677\n",
            "Epoch: 17 \tTraining Loss: 0.888077 \tValidation Loss: 0.664708\n",
            "Epoch: 18 \tTraining Loss: 0.857459 \tValidation Loss: 0.662134\n",
            "Epoch: 19 \tTraining Loss: 0.854336 \tValidation Loss: 1.192020\n",
            "Epoch: 20 \tTraining Loss: 0.855383 \tValidation Loss: 0.680236\n",
            "Epoch: 21 \tTraining Loss: 0.890706 \tValidation Loss: 0.667053\n",
            "Epoch: 22 \tTraining Loss: 0.837864 \tValidation Loss: 0.644421\n",
            "Epoch: 23 \tTraining Loss: 0.858915 \tValidation Loss: 0.663116\n",
            "Epoch: 24 \tTraining Loss: 0.869856 \tValidation Loss: 0.605625\n",
            "Epoch: 25 \tTraining Loss: 0.863460 \tValidation Loss: 0.656053\n",
            "Epoch: 26 \tTraining Loss: 0.832373 \tValidation Loss: 0.616322\n",
            "Epoch: 27 \tTraining Loss: 0.834906 \tValidation Loss: 0.690794\n",
            "Epoch: 28 \tTraining Loss: 0.849277 \tValidation Loss: 0.909447\n",
            "Epoch: 29 \tTraining Loss: 0.803139 \tValidation Loss: 0.680388\n",
            "Epoch: 30 \tTraining Loss: 0.815557 \tValidation Loss: 0.634711\n",
            "Epoch: 31 \tTraining Loss: 0.825241 \tValidation Loss: 0.688144\n",
            "Epoch: 32 \tTraining Loss: 0.802865 \tValidation Loss: 1.048392\n",
            "Epoch: 33 \tTraining Loss: 0.828804 \tValidation Loss: 0.786655\n",
            "Epoch: 34 \tTraining Loss: 0.843511 \tValidation Loss: 0.702918\n",
            "Epoch: 35 \tTraining Loss: 0.848496 \tValidation Loss: 0.727973\n",
            "Epoch: 36 \tTraining Loss: 0.834904 \tValidation Loss: 0.713750\n",
            "Epoch: 37 \tTraining Loss: 0.835872 \tValidation Loss: 0.714406\n",
            "Epoch: 38 \tTraining Loss: 0.809014 \tValidation Loss: 0.726126\n",
            "Epoch: 39 \tTraining Loss: 0.818810 \tValidation Loss: 0.772335\n",
            "Epoch: 40 \tTraining Loss: 0.818356 \tValidation Loss: 0.710197\n",
            "Epoch: 41 \tTraining Loss: 0.768559 \tValidation Loss: 0.845453\n",
            "Epoch: 42 \tTraining Loss: 0.824883 \tValidation Loss: 0.726549\n",
            "Epoch: 43 \tTraining Loss: 0.826920 \tValidation Loss: 0.922809\n",
            "Epoch: 44 \tTraining Loss: 0.776654 \tValidation Loss: 0.744586\n",
            "Epoch: 45 \tTraining Loss: 0.794281 \tValidation Loss: 0.771456\n",
            "Epoch: 46 \tTraining Loss: 0.786978 \tValidation Loss: 0.782355\n",
            "Epoch: 47 \tTraining Loss: 0.831103 \tValidation Loss: 0.789575\n",
            "Epoch: 48 \tTraining Loss: 0.807004 \tValidation Loss: 0.793224\n",
            "Epoch: 49 \tTraining Loss: 0.817438 \tValidation Loss: 0.880086\n",
            "Epoch: 50 \tTraining Loss: 0.818956 \tValidation Loss: 0.827491\n",
            "Epoch: 51 \tTraining Loss: 0.801220 \tValidation Loss: 0.738743\n",
            "Epoch: 52 \tTraining Loss: 0.821751 \tValidation Loss: 0.766193\n",
            "Epoch: 53 \tTraining Loss: 0.801837 \tValidation Loss: 0.753671\n",
            "Epoch: 54 \tTraining Loss: 0.842506 \tValidation Loss: 0.736104\n",
            "Epoch: 55 \tTraining Loss: 0.803703 \tValidation Loss: 0.755894\n",
            "Epoch: 56 \tTraining Loss: 0.809431 \tValidation Loss: 0.743628\n",
            "Epoch: 57 \tTraining Loss: 0.803333 \tValidation Loss: 0.745069\n",
            "Epoch: 58 \tTraining Loss: 0.815818 \tValidation Loss: 0.834314\n",
            "Epoch: 59 \tTraining Loss: 0.805643 \tValidation Loss: 0.862251\n",
            "Epoch: 60 \tTraining Loss: 0.769467 \tValidation Loss: 0.753580\n",
            "Epoch: 61 \tTraining Loss: 0.827701 \tValidation Loss: 0.725078\n",
            "Epoch: 62 \tTraining Loss: 0.787318 \tValidation Loss: 0.741381\n",
            "Epoch: 63 \tTraining Loss: 0.810066 \tValidation Loss: 1.088999\n",
            "Epoch: 64 \tTraining Loss: 0.813053 \tValidation Loss: 0.873676\n",
            "Epoch: 65 \tTraining Loss: 0.806297 \tValidation Loss: 0.733560\n",
            "Epoch: 66 \tTraining Loss: 0.831668 \tValidation Loss: 0.721070\n",
            "Epoch: 67 \tTraining Loss: 0.775006 \tValidation Loss: 0.741453\n",
            "Epoch: 68 \tTraining Loss: 0.777148 \tValidation Loss: 0.752184\n",
            "Epoch: 69 \tTraining Loss: 0.821119 \tValidation Loss: 0.846563\n",
            "Epoch: 70 \tTraining Loss: 0.819890 \tValidation Loss: 0.780046\n",
            "Epoch: 71 \tTraining Loss: 0.794320 \tValidation Loss: 0.888344\n",
            "Epoch: 72 \tTraining Loss: 0.798050 \tValidation Loss: 0.785070\n",
            "Epoch: 73 \tTraining Loss: 0.815959 \tValidation Loss: 1.112485\n",
            "Epoch: 74 \tTraining Loss: 0.816316 \tValidation Loss: 0.743670\n",
            "Epoch: 75 \tTraining Loss: 0.834896 \tValidation Loss: 0.750842\n",
            "Epoch: 76 \tTraining Loss: 0.814776 \tValidation Loss: 0.790534\n",
            "Epoch: 77 \tTraining Loss: 0.771750 \tValidation Loss: 0.750981\n",
            "Epoch: 78 \tTraining Loss: 0.818329 \tValidation Loss: 0.716197\n",
            "Epoch: 79 \tTraining Loss: 0.840446 \tValidation Loss: 0.725184\n",
            "Epoch: 80 \tTraining Loss: 0.799635 \tValidation Loss: 0.778522\n",
            "Epoch: 81 \tTraining Loss: 0.806176 \tValidation Loss: 0.717388\n",
            "Epoch: 82 \tTraining Loss: 0.805874 \tValidation Loss: 0.727270\n",
            "Epoch: 83 \tTraining Loss: 0.826724 \tValidation Loss: 0.698352\n",
            "Epoch: 84 \tTraining Loss: 0.793020 \tValidation Loss: 0.804638\n",
            "Epoch: 85 \tTraining Loss: 0.817320 \tValidation Loss: 0.901470\n",
            "Epoch: 86 \tTraining Loss: 0.817682 \tValidation Loss: 0.901382\n",
            "Epoch: 87 \tTraining Loss: 0.781536 \tValidation Loss: 0.726051\n",
            "Epoch: 88 \tTraining Loss: 0.798680 \tValidation Loss: 0.912793\n",
            "Epoch: 89 \tTraining Loss: 0.814127 \tValidation Loss: 0.933381\n",
            "Epoch: 90 \tTraining Loss: 0.821510 \tValidation Loss: 0.751030\n",
            "Epoch: 91 \tTraining Loss: 0.798769 \tValidation Loss: 0.733792\n",
            "Epoch: 92 \tTraining Loss: 0.835251 \tValidation Loss: 0.777806\n",
            "Epoch: 93 \tTraining Loss: 0.795450 \tValidation Loss: 0.869815\n",
            "Epoch: 94 \tTraining Loss: 0.802062 \tValidation Loss: 1.053309\n",
            "Epoch: 95 \tTraining Loss: 0.811779 \tValidation Loss: 0.733431\n",
            "Epoch: 96 \tTraining Loss: 0.846562 \tValidation Loss: 0.845960\n",
            "Epoch: 97 \tTraining Loss: 0.798549 \tValidation Loss: 0.767721\n",
            "Epoch: 98 \tTraining Loss: 0.817326 \tValidation Loss: 0.823428\n",
            "Epoch: 99 \tTraining Loss: 0.794699 \tValidation Loss: 0.948653\n",
            "Epoch: 100 \tTraining Loss: 0.809020 \tValidation Loss: 0.937937\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KzD-OTdmIr_G",
        "outputId": "7078bdf2-4fbc-4019-e9ae-10dfcedf8b71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "test(dataloaders, inception_3, criterion_inception, device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.779765\n",
            "\n",
            "\n",
            "Test Accuracy: 83% (698/836)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZipxs5yw0Q8"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "### TODO: select loss function\n",
        "criterion_exp = nn.CrossEntropyLoss()\n",
        "\n",
        "### TODO: select optimizer\n",
        "optimizer_exp = optim.Adam(inception.parameters())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVGfxSVdyxNK"
      },
      "source": [
        "import math\n",
        "def train_exp(n_epochs, loaders, model, optimizer, criterion, device, save_path, initial_rate = 0.1, k=0.1):\n",
        "    \"\"\"returns trained model\"\"\"\n",
        "    # initialize tracker for minimum validation loss\n",
        "    valid_loss_min = np.Inf \n",
        "    \n",
        "    for epoch in range(1, n_epochs+1):\n",
        "        # initialize variables to monitor training and validation loss\n",
        "        train_loss = 0.0\n",
        "        valid_loss = 0.0\n",
        "\n",
        "        #Exponential Decay\n",
        "        #lr = initial_rate * exp(-k*t)\n",
        "        #initial_rate = 0.1\n",
        "        #k = 0.1\n",
        "\n",
        "        lr = initial_rate * math.exp(-k*epoch)    \n",
        "        print('The learning rate was set to {}.'.format(lr))\n",
        "        for param_group in optimizer.param_groups:\n",
        "                    param_group['lr'] = lr\n",
        "        \n",
        "        ###################\n",
        "        # train the model #\n",
        "        ###################\n",
        "        model.train()\n",
        "        for batch_idx, (data, target) in enumerate(loaders['train']):\n",
        "            \n",
        "            # move to GPU or CPU\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            \n",
        "            ## find the loss and update the model parameters accordingly\n",
        "            ## record the average training loss, using something like\n",
        "            ## train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            \n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            train_loss += ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n",
        "            \n",
        "        ######################    \n",
        "        # validate the model #\n",
        "        ######################\n",
        "        model.eval()\n",
        "        for batch_idx, (data, target) in enumerate(loaders['valid']):\n",
        "            # move to GPU or CPU\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            \n",
        "            ## update the average validation loss\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            \n",
        "            valid_loss += ((1 / (batch_idx + 1)) * (loss.data - valid_loss))\n",
        "            \n",
        "        # print training/validation statistics \n",
        "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
        "            epoch, \n",
        "            train_loss,\n",
        "            valid_loss\n",
        "            ))\n",
        "        \n",
        "        ## TODO: save the model if validation loss has decreased\n",
        "        if valid_loss < valid_loss_min:\n",
        "            print('Saving model..')\n",
        "            valid_loss_min = valid_loss\n",
        "            torch.save(model.state_dict(), save_path)\n",
        "            \n",
        "    # return trained model\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKI3HYMEVQoP",
        "outputId": "327a37ec-0163-46c5-f117-1235f7757757",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "inceptionv3 = train_exp(100, dataloaders, inception, optimizer_exp, \n",
        "                      criterion_exp, device, 'inceptionv3.pt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The learning rate was set to 0.09048374180359596.\n",
            "Epoch: 1 \tTraining Loss: 70.206329 \tValidation Loss: 70.682030\n",
            "Saving model..\n",
            "The learning rate was set to 0.0818730753077982.\n",
            "Epoch: 2 \tTraining Loss: 72.522659 \tValidation Loss: 67.528595\n",
            "Saving model..\n",
            "The learning rate was set to 0.0740818220681718.\n",
            "Epoch: 3 \tTraining Loss: 69.801796 \tValidation Loss: 66.645844\n",
            "Saving model..\n",
            "The learning rate was set to 0.06703200460356394.\n",
            "Epoch: 4 \tTraining Loss: 68.832458 \tValidation Loss: 70.043900\n",
            "The learning rate was set to 0.06065306597126335.\n",
            "Epoch: 5 \tTraining Loss: 67.496941 \tValidation Loss: 82.717194\n",
            "The learning rate was set to 0.05488116360940264.\n",
            "Epoch: 6 \tTraining Loss: 65.904480 \tValidation Loss: 81.053513\n",
            "The learning rate was set to 0.04965853037914095.\n",
            "Epoch: 7 \tTraining Loss: 63.521393 \tValidation Loss: 67.319901\n",
            "The learning rate was set to 0.044932896411722156.\n",
            "Epoch: 8 \tTraining Loss: 63.913483 \tValidation Loss: 64.592857\n",
            "Saving model..\n",
            "The learning rate was set to 0.04065696597405991.\n",
            "Epoch: 9 \tTraining Loss: 66.733948 \tValidation Loss: 62.181618\n",
            "Saving model..\n",
            "The learning rate was set to 0.036787944117144235.\n",
            "Epoch: 10 \tTraining Loss: 63.916714 \tValidation Loss: 60.648350\n",
            "Saving model..\n",
            "The learning rate was set to 0.03328710836980796.\n",
            "Epoch: 11 \tTraining Loss: 61.291412 \tValidation Loss: 64.475441\n",
            "The learning rate was set to 0.030119421191220203.\n",
            "Epoch: 12 \tTraining Loss: 63.100170 \tValidation Loss: 61.644379\n",
            "The learning rate was set to 0.02725317930340126.\n",
            "Epoch: 13 \tTraining Loss: 64.417870 \tValidation Loss: 64.783417\n",
            "The learning rate was set to 0.024659696394160643.\n",
            "Epoch: 14 \tTraining Loss: 58.962399 \tValidation Loss: 77.728455\n",
            "The learning rate was set to 0.022313016014842982.\n",
            "Epoch: 15 \tTraining Loss: 59.511456 \tValidation Loss: 62.023190\n",
            "The learning rate was set to 0.02018965179946554.\n",
            "Epoch: 16 \tTraining Loss: 62.427746 \tValidation Loss: 65.693825\n",
            "The learning rate was set to 0.018268352405273462.\n",
            "Epoch: 17 \tTraining Loss: 59.215405 \tValidation Loss: 63.234344\n",
            "The learning rate was set to 0.016529888822158653.\n",
            "Epoch: 18 \tTraining Loss: 56.267216 \tValidation Loss: 62.842796\n",
            "The learning rate was set to 0.014956861922263504.\n",
            "Epoch: 19 \tTraining Loss: 60.556721 \tValidation Loss: 81.175751\n",
            "The learning rate was set to 0.013533528323661271.\n",
            "Epoch: 20 \tTraining Loss: 58.071053 \tValidation Loss: 83.289978\n",
            "The learning rate was set to 0.012245642825298192.\n",
            "Epoch: 21 \tTraining Loss: 59.550987 \tValidation Loss: 89.689522\n",
            "The learning rate was set to 0.011080315836233388.\n",
            "Epoch: 22 \tTraining Loss: 59.900955 \tValidation Loss: 67.493362\n",
            "The learning rate was set to 0.010025884372280372.\n",
            "Epoch: 23 \tTraining Loss: 55.786030 \tValidation Loss: 63.795063\n",
            "The learning rate was set to 0.009071795328941248.\n",
            "Epoch: 24 \tTraining Loss: 60.075928 \tValidation Loss: 59.533108\n",
            "Saving model..\n",
            "The learning rate was set to 0.008208499862389881.\n",
            "Epoch: 25 \tTraining Loss: 58.109158 \tValidation Loss: 60.166634\n",
            "The learning rate was set to 0.007427357821433388.\n",
            "Epoch: 26 \tTraining Loss: 57.875820 \tValidation Loss: 59.477684\n",
            "Saving model..\n",
            "The learning rate was set to 0.006720551273974976.\n",
            "Epoch: 27 \tTraining Loss: 57.111607 \tValidation Loss: 61.002930\n",
            "The learning rate was set to 0.006081006262521796.\n",
            "Epoch: 28 \tTraining Loss: 54.484715 \tValidation Loss: 62.984398\n",
            "The learning rate was set to 0.005502322005640721.\n",
            "Epoch: 29 \tTraining Loss: 58.505608 \tValidation Loss: 61.427429\n",
            "The learning rate was set to 0.004978706836786395.\n",
            "Epoch: 30 \tTraining Loss: 54.642456 \tValidation Loss: 59.807610\n",
            "The learning rate was set to 0.00450492023935578.\n",
            "Epoch: 31 \tTraining Loss: 57.072987 \tValidation Loss: 59.458050\n",
            "Saving model..\n",
            "The learning rate was set to 0.0040762203978366215.\n",
            "Epoch: 32 \tTraining Loss: 57.073063 \tValidation Loss: 59.112934\n",
            "Saving model..\n",
            "The learning rate was set to 0.0036883167401239995.\n",
            "Epoch: 33 \tTraining Loss: 56.956642 \tValidation Loss: 59.116879\n",
            "The learning rate was set to 0.003337326996032607.\n",
            "Epoch: 34 \tTraining Loss: 56.419209 \tValidation Loss: 59.957207\n",
            "The learning rate was set to 0.00301973834223185.\n",
            "Epoch: 35 \tTraining Loss: 57.174828 \tValidation Loss: 61.973660\n",
            "The learning rate was set to 0.0027323722447292562.\n",
            "Epoch: 36 \tTraining Loss: 55.269932 \tValidation Loss: 56.142212\n",
            "Saving model..\n",
            "The learning rate was set to 0.002472352647033939.\n",
            "Epoch: 37 \tTraining Loss: 54.287643 \tValidation Loss: 57.918674\n",
            "The learning rate was set to 0.002237077185616559.\n",
            "Epoch: 38 \tTraining Loss: 57.812847 \tValidation Loss: 58.316292\n",
            "The learning rate was set to 0.002024191144580438.\n",
            "Epoch: 39 \tTraining Loss: 57.568844 \tValidation Loss: 58.933548\n",
            "The learning rate was set to 0.001831563888873418.\n",
            "Epoch: 40 \tTraining Loss: 57.115231 \tValidation Loss: 58.906612\n",
            "The learning rate was set to 0.001657267540176124.\n",
            "Epoch: 41 \tTraining Loss: 58.140827 \tValidation Loss: 65.472267\n",
            "The learning rate was set to 0.0014995576820477704.\n",
            "Epoch: 42 \tTraining Loss: 56.716343 \tValidation Loss: 58.103916\n",
            "The learning rate was set to 0.0013568559012200935.\n",
            "Epoch: 43 \tTraining Loss: 54.004822 \tValidation Loss: 61.443184\n",
            "The learning rate was set to 0.0012277339903068436.\n",
            "Epoch: 44 \tTraining Loss: 56.609585 \tValidation Loss: 59.111504\n",
            "The learning rate was set to 0.0011108996538242307.\n",
            "Epoch: 45 \tTraining Loss: 53.859615 \tValidation Loss: 58.254234\n",
            "The learning rate was set to 0.0010051835744633575.\n",
            "Epoch: 46 \tTraining Loss: 56.999161 \tValidation Loss: 58.091232\n",
            "The learning rate was set to 0.0009095277101695816.\n",
            "Epoch: 47 \tTraining Loss: 56.259972 \tValidation Loss: 63.978657\n",
            "The learning rate was set to 0.0008229747049020024.\n",
            "Epoch: 48 \tTraining Loss: 54.709801 \tValidation Loss: 63.501842\n",
            "The learning rate was set to 0.0007446583070924339.\n",
            "Epoch: 49 \tTraining Loss: 56.004757 \tValidation Loss: 56.463982\n",
            "The learning rate was set to 0.0006737946999085467.\n",
            "Epoch: 50 \tTraining Loss: 53.658855 \tValidation Loss: 60.648003\n",
            "The learning rate was set to 0.0006096746565515633.\n",
            "Epoch: 51 \tTraining Loss: 55.092075 \tValidation Loss: 63.117153\n",
            "The learning rate was set to 0.0005516564420760772.\n",
            "Epoch: 52 \tTraining Loss: 54.280407 \tValidation Loss: 76.841148\n",
            "The learning rate was set to 0.0004991593906910213.\n",
            "Epoch: 53 \tTraining Loss: 57.082634 \tValidation Loss: 76.868546\n",
            "The learning rate was set to 0.0004516580942612666.\n",
            "Epoch: 54 \tTraining Loss: 57.703133 \tValidation Loss: 58.860771\n",
            "The learning rate was set to 0.00040867714384640666.\n",
            "Epoch: 55 \tTraining Loss: 56.712585 \tValidation Loss: 72.208336\n",
            "The learning rate was set to 0.0003697863716482929.\n",
            "Epoch: 56 \tTraining Loss: 56.448597 \tValidation Loss: 63.087685\n",
            "The learning rate was set to 0.0003345965457471272.\n",
            "Epoch: 57 \tTraining Loss: 58.421261 \tValidation Loss: 59.845448\n",
            "The learning rate was set to 0.0003027554745375813.\n",
            "Epoch: 58 \tTraining Loss: 55.577820 \tValidation Loss: 59.518429\n",
            "The learning rate was set to 0.00027394448187683686.\n",
            "Epoch: 59 \tTraining Loss: 58.990959 \tValidation Loss: 67.780991\n",
            "The learning rate was set to 0.00024787521766663585.\n",
            "Epoch: 60 \tTraining Loss: 58.553120 \tValidation Loss: 86.536926\n",
            "The learning rate was set to 0.00022428677194858012.\n",
            "Epoch: 61 \tTraining Loss: 56.983662 \tValidation Loss: 59.256531\n",
            "The learning rate was set to 0.00020294306362957342.\n",
            "Epoch: 62 \tTraining Loss: 58.587883 \tValidation Loss: 58.423065\n",
            "The learning rate was set to 0.00018363047770289057.\n",
            "Epoch: 63 \tTraining Loss: 56.201180 \tValidation Loss: 57.405190\n",
            "The learning rate was set to 0.0001661557273173934.\n",
            "Epoch: 64 \tTraining Loss: 57.199844 \tValidation Loss: 59.469440\n",
            "The learning rate was set to 0.00015034391929775724.\n",
            "Epoch: 65 \tTraining Loss: 56.171646 \tValidation Loss: 64.260452\n",
            "The learning rate was set to 0.00013603680375478928.\n",
            "Epoch: 66 \tTraining Loss: 57.084019 \tValidation Loss: 82.296921\n",
            "The learning rate was set to 0.0001230911902673481.\n",
            "Epoch: 67 \tTraining Loss: 58.008827 \tValidation Loss: 59.458588\n",
            "The learning rate was set to 0.00011137751478448025.\n",
            "Epoch: 68 \tTraining Loss: 53.717899 \tValidation Loss: 71.385704\n",
            "The learning rate was set to 0.00010077854290485106.\n",
            "Epoch: 69 \tTraining Loss: 55.139477 \tValidation Loss: 58.757660\n",
            "The learning rate was set to 9.118819655545162e-05.\n",
            "Epoch: 70 \tTraining Loss: 57.523674 \tValidation Loss: 58.749146\n",
            "The learning rate was set to 8.251049232659039e-05.\n",
            "Epoch: 71 \tTraining Loss: 55.306828 \tValidation Loss: 59.772301\n",
            "The learning rate was set to 7.465858083766792e-05.\n",
            "Epoch: 72 \tTraining Loss: 58.461643 \tValidation Loss: 62.836975\n",
            "The learning rate was set to 6.755387751938438e-05.\n",
            "Epoch: 73 \tTraining Loss: 55.133282 \tValidation Loss: 58.173145\n",
            "The learning rate was set to 6.112527611295723e-05.\n",
            "Epoch: 74 \tTraining Loss: 57.012150 \tValidation Loss: 66.817085\n",
            "The learning rate was set to 5.530843701478336e-05.\n",
            "Epoch: 75 \tTraining Loss: 56.012192 \tValidation Loss: 61.220848\n",
            "The learning rate was set to 5.004514334406104e-05.\n",
            "Epoch: 76 \tTraining Loss: 54.565735 \tValidation Loss: 58.577011\n",
            "The learning rate was set to 4.52827182886797e-05.\n",
            "Epoch: 77 \tTraining Loss: 53.605976 \tValidation Loss: 64.442848\n",
            "The learning rate was set to 4.097349789797865e-05.\n",
            "Epoch: 78 \tTraining Loss: 53.465454 \tValidation Loss: 66.823227\n",
            "The learning rate was set to 3.7074354045908826e-05.\n",
            "Epoch: 79 \tTraining Loss: 56.896751 \tValidation Loss: 58.393959\n",
            "The learning rate was set to 3.354626279025119e-05.\n",
            "Epoch: 80 \tTraining Loss: 55.509850 \tValidation Loss: 62.053139\n",
            "The learning rate was set to 3.035391380788668e-05.\n",
            "Epoch: 81 \tTraining Loss: 56.291683 \tValidation Loss: 60.102310\n",
            "The learning rate was set to 2.7465356997214206e-05.\n",
            "Epoch: 82 \tTraining Loss: 53.135807 \tValidation Loss: 60.886066\n",
            "The learning rate was set to 2.4851682710795188e-05.\n",
            "Epoch: 83 \tTraining Loss: 55.574593 \tValidation Loss: 80.566765\n",
            "The learning rate was set to 2.248673241788482e-05.\n",
            "Epoch: 84 \tTraining Loss: 55.727802 \tValidation Loss: 93.256851\n",
            "The learning rate was set to 2.0346836901064418e-05.\n",
            "Epoch: 85 \tTraining Loss: 56.129551 \tValidation Loss: 62.475288\n",
            "The learning rate was set to 1.841057936675792e-05.\n",
            "Epoch: 86 \tTraining Loss: 57.481331 \tValidation Loss: 57.153847\n",
            "The learning rate was set to 1.6658581098763325e-05.\n",
            "Epoch: 87 \tTraining Loss: 57.545006 \tValidation Loss: 59.949986\n",
            "The learning rate was set to 1.5073307509547651e-05.\n",
            "Epoch: 88 \tTraining Loss: 56.113007 \tValidation Loss: 58.093468\n",
            "The learning rate was set to 1.363889264820114e-05.\n",
            "Epoch: 89 \tTraining Loss: 54.167931 \tValidation Loss: 78.076302\n",
            "The learning rate was set to 1.2340980408667957e-05.\n",
            "Epoch: 90 \tTraining Loss: 54.898857 \tValidation Loss: 58.323570\n",
            "The learning rate was set to 1.1166580849011478e-05.\n",
            "Epoch: 91 \tTraining Loss: 55.401535 \tValidation Loss: 59.387138\n",
            "The learning rate was set to 1.0103940183709325e-05.\n",
            "Epoch: 92 \tTraining Loss: 57.262764 \tValidation Loss: 58.524654\n",
            "The learning rate was set to 9.142423147817328e-06.\n",
            "Epoch: 93 \tTraining Loss: 55.704319 \tValidation Loss: 57.958969\n",
            "The learning rate was set to 8.272406555663223e-06.\n",
            "Epoch: 94 \tTraining Loss: 53.870426 \tValidation Loss: 59.108536\n",
            "The learning rate was set to 7.48518298877006e-06.\n",
            "Epoch: 95 \tTraining Loss: 57.075424 \tValidation Loss: 59.288601\n",
            "The learning rate was set to 6.772873649085378e-06.\n",
            "Epoch: 96 \tTraining Loss: 56.999557 \tValidation Loss: 59.855572\n",
            "The learning rate was set to 6.128349505322203e-06.\n",
            "Epoch: 97 \tTraining Loss: 56.608459 \tValidation Loss: 59.714256\n",
            "The learning rate was set to 5.545159943217695e-06.\n",
            "Epoch: 98 \tTraining Loss: 55.357872 \tValidation Loss: 59.919113\n",
            "The learning rate was set to 5.017468205617529e-06.\n",
            "Epoch: 99 \tTraining Loss: 56.807262 \tValidation Loss: 70.974747\n",
            "The learning rate was set to 4.539992976248485e-06.\n",
            "Epoch: 100 \tTraining Loss: 54.626854 \tValidation Loss: 58.000175\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqDJ_g2GV9lk",
        "outputId": "810685bf-a050-4693-a21c-27d6f066e971",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "inception.load_state_dict(torch.load('inceptionv3.pt'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVMrrADFWD_X",
        "outputId": "fe58e9c4-2791-4ce4-8510-fd509fb5f8cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "test(dataloaders, inceptionv3, criterion_exp, device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 50.441177\n",
            "\n",
            "\n",
            "Test Accuracy: 84% (706/836)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qCImkrR6i54"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}